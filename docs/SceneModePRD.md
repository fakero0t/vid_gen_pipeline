# Unified Storyboard Interface - Product Requirements Document

## Overview

The Unified Storyboard Interface consolidates the current multi-step video creation workflow into a single, cohesive experience. Instead of separating storyboard creation, image generation, and video generation into distinct screens, this feature allows users to progressively enhance each scene independently—from text description to image to final video clip—all within one interface.

**Problem it solves:** The current workflow forces users through rigid sequential steps where all scenes must complete one phase before moving to the next. This creates unnecessary waiting time and limits creative flexibility.

**Target users:** Content creators and marketers using the video generation platform who need granular control over individual scenes while maintaining a clear overview of their entire project.

**Value proposition:** Users can work on scenes in any order, immediately see progress across their entire storyboard, and make iterative improvements to individual scenes without affecting others.

---

## Core Features

### 1. Progressive Scene States
Each scene exists in one of three states: **Text**, **Image**, or **Video**. Users can only progress forward through these states by approving each level, but can revert backward by editing earlier elements.

**Why it's important:** Provides flexibility while maintaining quality control—users must explicitly approve each stage before investing resources in the next generation step.

**How it works:**
- **Text State**: Displays scene description only. User can edit manually or regenerate with AI.
- **Image State**: Shows generated image with text below. User can configure video duration (default 5 seconds).
- **Video State**: Displays generated video clip with image thumbnail and text below. User can play inline.

### 2. Approval & Regeneration Workflow
Each state requires explicit approval via checkmark button before advancing. Each element can be independently regenerated.

**Why it's important:** Prevents wasting computational resources on unwanted content while giving users control to iterate on any element.

**How it works:**
- **Approval**: Checkmark button visible in Text and Image states. Approving advances to next state and triggers generation.
- **Regeneration**: Separate regenerate buttons for text, image, and video. Regenerating an earlier element triggers warning modal and deletes subsequent elements.
- **Edit Protection**: Text and duration only editable in appropriate states. Edit icon with warning modal in later states.

### 3. Timeline-Based Navigation
Horizontal timeline at top shows all scenes with color-coded states. Clicking a scene jumps to that scene card.

**Why it's important:** Provides spatial awareness of progress and allows quick navigation across scenes without scrolling.

**How it works:**
- Color coding: Gray (Text), Yellow (Image), Green (Video), Red (Error)
- Pulsing animation during generation
- Click to jump to scene (carousel scrolls horizontally)
- Locked horizontal scrolling (only timeline controls navigation)

### 4. Carousel Scene Display
Single scene visible at a time in full-width card. Only way to switch scenes is via timeline selection.

**Why it's important:** Focuses user attention on one scene at a time while maintaining overview via timeline.

**How it works:**
- One scene card visible at full width
- Smooth horizontal scroll animation when switching scenes
- Scene number badge in upper left corner
- State-specific layout (text only → image + text → video + thumbnail + text)

### 5. Concatenated Preview
"Preview All Scenes" button generates full video preview using available content. Scenes without videos show placeholders.

**Why it's important:** Allows users to see their progress and overall video flow before all scenes are complete.

**How it works:**
- Button at top of page
- Opens dedicated preview area with full video player
- For incomplete scenes: Use image (if available) with configured/default duration (5s), or text display if no image

### 6. Background Video Generation
Video generation happens asynchronously while users continue working on other scenes.

**Why it's important:** Eliminates waiting time and allows parallel progress across multiple scenes.

**How it works:**
- Progress indicator in scene card during generation
- User can switch to other scenes immediately
- Success/error states update in real-time

### 7. Persistent State Management
All scene states, content, and progress persisted to backend. Page refreshes or returning to app recovers full state.

**Why it's important:** Prevents data loss and allows users to work across multiple sessions.

**How it works:**
- Scene IDs as UUIDs generated by backend
- Storyboard data model tracks scene order and individual scene states
- Automatic save on every state change
- Session/user context handled by authentication layer

---

## User Experience

### User Persona
**Creative Content Manager (primary)**: Marketing professional creating short-form video ads. Needs quick iteration cycles and the ability to perfect individual scenes without redoing entire videos. Values visual feedback and granular control.

### Key User Flows

#### Flow 1: Initial Storyboard Generation
1. User completes creative brief and selects mood (previous steps)
2. Arrives at storyboard page
3. Loading state displays while 6 scene texts are generated automatically based on creative brief and mood
4. Timeline appears with 6 gray (Text state) scene markers
5. Scene 1 displayed in carousel by default

#### Flow 2: Progressing a Scene (Text → Image → Video)
1. User reviews scene text in Text state
2. User approves (checkmark) or regenerates text
3. Upon approval, scene advances to Image state and image generation begins
4. Timeline updates scene to yellow (Image state) with loading animation
5. Generated image displays with text below
6. User sets video duration (default 5s shown)
7. User approves image (and duration)
8. Scene advances to Video state and video generation begins in background
9. Timeline updates to green (Video state) with loading animation
10. User can immediately switch to another scene via timeline
11. When complete, video appears with play button

#### Flow 3: Editing Earlier Elements (Reverting States)
1. User in Image or Video state
2. Clicks Edit icon next to text
3. Warning modal appears: "Editing text will erase image and video. This cannot be undone."
4. User confirms or cancels
5. If confirmed: Scene reverts to Text state, image/video deleted
6. User edits text manually or regenerates with AI
7. Process restarts from Text state

#### Flow 4: Editing Duration from Video State
1. User in Video state with completed video
2. Clicks Edit icon next to duration
3. Warning modal appears: "Editing duration will erase video. This cannot be undone."
4. User confirms or cancels
5. If confirmed: Video deleted, scene reverts to Image state (image and text preserved)
6. User modifies duration
7. User approves Image state again
8. New video generates with updated duration

#### Flow 5: Regenerating All Scenes
1. User clicks "Regenerate All Scenes" button
2. Warning modal: "All scenes and progress will be erased. This cannot be undone."
3. User confirms or cancels
4. If confirmed: All scenes reset to Text state, all images/videos deleted
5. 6 new scene texts generated based on original creative brief and mood
6. User starts fresh workflow

#### Flow 6: Previewing Progress
1. User clicks "Preview All Scenes" at top
2. Dedicated preview area opens with video player
3. Concatenated video plays:
   - Completed videos play normally
   - Image-only scenes show image for configured/default duration
   - Text-only scenes show text display for 5 seconds
4. User sees full video flow with placeholders

#### Flow 7: Final Video Generation
1. All 6 scenes in Video state (green on timeline)
2. "Generate Final Video" button enabled at top
3. Status shows "6/6 scenes ready" below button
4. User clicks button
5. Navigates to separate final composition screen (existing feature)

### UI/UX Considerations

**Layout Structure:**
- Timeline fixed at top (always visible)
- "Preview All Scenes" and "Regenerate All Scenes" buttons below timeline
- Carousel scene card occupies main area
- "Generate Final Video" button appears when all scenes complete (6/6 ready indicator)

**Scene Card Components:**
- **Text State**: Text field, checkmark button, regenerate text button (AI icon)
- **Image State**: Image (top), text below, duration input, checkmark button, regenerate image button, edit icon (for text)
- **Video State**: Video player with play button (top), image thumbnail below, text below, duration display, regenerate video button, edit icon (for text and duration)

**Visual Feedback:**
- Modal dialogs for destructive actions (blocking, requires Yes/No confirmation)
- Inline error messages in scene cards for generation failures
- Toast notifications at top of screen for errors
- Loading states during generation (text, image, video)
- Smooth carousel transitions (horizontal scroll)
- Timeline color coding and animations

**Accessibility:**
- Edit icon tooltips ("Edit text (will erase image/video)", "Edit duration (will erase video)")
- Clear error states prevent final video generation
- Explicit approval steps prevent accidental progression
- Warning modals prevent accidental data loss

---

## Technical Architecture

### System Components

**Frontend (Next.js/React):**
- `StoryboardCarousel.tsx`: Main container with timeline and carousel logic
- `SceneCard.tsx`: Individual scene card with state-specific rendering
- `SceneTimeline.tsx`: Timeline component with color-coded states and navigation
- `PreviewPlayer.tsx`: Concatenated preview with placeholder handling
- `WarningModal.tsx`: Reusable confirmation dialog for destructive actions
- State management via Zustand (existing store pattern)

**Backend (FastAPI/Python):**
- New scene management endpoints (detailed below)
- Storyboard persistence layer
- Async job management for video generation
- SSE (Server-Sent Events) for real-time progress updates

**External Services:**
- Replicate API for image generation (existing)
- Replicate API for video generation (existing)
- AI service for text generation (existing)

### Data Models

**Storyboard Model:**
```typescript
interface Storyboard {
  storyboard_id: string; // UUID
  session_id: string; // From auth layer
  user_id: string; // From auth layer
  created_at: timestamp;
  updated_at: timestamp;
  scene_order: string[]; // Array of scene IDs (UUIDs)
  creative_brief: CreativeBrief; // From previous step
  selected_mood: Mood; // From previous step
}
```

**Scene Model:**
```typescript
interface Scene {
  id: string; // UUID (backend-generated)
  storyboard_id: string; // Foreign key
  state: 'text' | 'image' | 'video';
  text: string;
  style_prompt: string; // From mood selection
  image_url?: string | null;
  seed_image_urls?: string[] | null;
  video_url?: string | null;
  video_duration: number; // Default 5
  generation_status: {
    image?: 'pending' | 'generating' | 'complete' | 'error';
    video?: 'pending' | 'generating' | 'complete' | 'error';
  };
  error_message?: string | null;
  created_at: timestamp;
  updated_at: timestamp;
}
```

### APIs and Integrations

**New Endpoints:**

1. `POST /api/storyboards/initialize`
   - Input: creative_brief, selected_mood
   - Output: storyboard with 6 generated scene texts
   - Triggers: AI text generation for all scenes

2. `GET /api/storyboards/{storyboard_id}`
   - Input: storyboard_id (from session context)
   - Output: Full storyboard with all scenes and current states
   - Use: Page load/refresh recovery

3. `PATCH /api/scenes/{scene_id}/text`
   - Input: scene_id, new_text (manual or AI-generated)
   - Output: Updated scene (state: 'text', image/video deleted)
   - Triggers: State revert if necessary

4. `POST /api/scenes/{scene_id}/generate-text`
   - Input: scene_id, creative_brief context
   - Output: Scene with new AI-generated text
   - Triggers: AI text generation

5. `POST /api/scenes/{scene_id}/generate-image`
   - Input: scene_id
   - Output: Scene with image URL (state: 'image')
   - Triggers: Replicate image generation job

6. `POST /api/scenes/{scene_id}/regenerate-image`
   - Input: scene_id
   - Output: Scene with new image URL
   - Triggers: Replicate image generation job (same parameters)

7. `PATCH /api/scenes/{scene_id}/duration`
   - Input: scene_id, new_duration
   - Output: Updated scene (state: 'image', video deleted if exists)
   - Triggers: State revert if in video state

8. `POST /api/scenes/{scene_id}/generate-video`
   - Input: scene_id
   - Output: Job ID for async video generation (state: 'video', status: 'generating')
   - Triggers: Replicate video generation job (async)

9. `POST /api/scenes/{scene_id}/regenerate-video`
   - Input: scene_id
   - Output: Job ID for async video generation
   - Triggers: Replicate video generation job (same parameters)

10. `GET /api/scenes/{scene_id}/status`
    - Input: scene_id
    - Output: Current generation status and any errors
    - Use: Polling for video generation progress

11. `POST /api/storyboards/{storyboard_id}/regenerate-all`
    - Input: storyboard_id
    - Output: Storyboard with 6 new scene texts (all states reset)
    - Triggers: Delete all images/videos, regenerate all texts

12. `GET /api/storyboards/{storyboard_id}/preview`
    - Input: storyboard_id
    - Output: Array of video URLs and placeholder data for preview concatenation
    - Use: Generate preview player data

13. `GET /api/storyboards/{storyboard_id}/events` (SSE)
    - Input: storyboard_id (from session context)
    - Output: Server-Sent Event stream with real-time updates
    - Events: `scene_update` (status, progress, URLs), `error`, `complete`
    - Use: Real-time progress updates for all scenes in storyboard

**Server-Sent Events (SSE):**
- Single SSE connection per storyboard for real-time updates
- Server pushes events when scene generation status changes
- Event types: `scene_update`, `error`, `complete`
- Automatic reconnection on network interruption
- Client subscribes on page load, unsubscribes on navigate away
- Fallback to polling (`GET /api/scenes/{scene_id}/status`) if SSE not supported (older browsers)

### Infrastructure Requirements

- **Database**: PostgreSQL for storyboard and scene persistence
- **Object Storage**: S3 or equivalent for image/video URLs
- **Job Queue**: Redis + Celery for async video generation jobs
- **SSE Support**: FastAPI StreamingResponse for Server-Sent Events
- **Caching**: Redis for scene status caching and SSE event broadcasting

---

## Development Roadmap

### Phase 1: Foundation & Data Layer (MVP Core)
**Goal**: Establish backend persistence and scene state management

- Design and implement database schema (Storyboard, Scene tables)
- Build storyboard initialization endpoint (POST /api/storyboards/initialize)
- Implement scene retrieval endpoint (GET /api/storyboards/{storyboard_id})
- Create text update endpoint (PATCH /api/scenes/{scene_id}/text)
- Set up UUID generation for scene IDs (backend)
- Implement basic error handling and validation
- Write unit tests for data models and endpoints

**Success Criteria**: Can create storyboard, generate 6 scene texts, persist to DB, retrieve on page refresh

### Phase 2: Frontend UI Components (Visual Foundation)
**Goal**: Build core UI components without generation logic

- Create StoryboardCarousel component with carousel structure
- Build SceneTimeline component with color-coded states
- Implement SceneCard component with three state layouts:
  - Text state: text field + buttons
  - Image state: image + text + duration input + buttons
  - Video state: video player + thumbnail + text + buttons
- Add timeline click navigation (scroll to scene)
- Implement WarningModal component for destructive actions
- Style all components with responsive design
- Add loading skeletons for each state

**Success Criteria**: Can navigate between scenes via timeline, see different state layouts (with mock data)

### Phase 3: Text State Workflow (First Working Loop)
**Goal**: Complete end-to-end workflow for text generation and editing

- Implement initial scene text generation on page load
- Add inline text editing functionality
- Build "Regenerate Text" (AI) button and endpoint integration (POST /api/scenes/{scene_id}/generate-text)
- Add "Approve" (checkmark) button for text state
- Implement warning modal for text editing from Image/Video states
- Connect state reversion logic (delete image/video when text edited)
- Add error handling and inline error messages
- Write integration tests for text workflow

**Success Criteria**: Can generate scene texts, edit manually, regenerate with AI, approve to advance (without actual image generation yet)

### Phase 4: Image State Workflow (Second Loop)
**Goal**: Add image generation and duration configuration

- Build image generation endpoint (POST /api/scenes/{scene_id}/generate-image)
- Implement image regeneration endpoint (POST /api/scenes/{scene_id}/regenerate-image)
- Connect Replicate API for image generation
- Add duration input field with validation (1-10 seconds)
- Implement duration update endpoint (PATCH /api/scenes/{scene_id}/duration)
- Add "Approve" button for image state (approves image + duration)
- Add "Regenerate Image" button
- Implement timeline color update (gray → yellow)
- Add loading states during image generation
- Handle image generation errors (inline + toast)

**Success Criteria**: Can generate images from approved text, configure duration, regenerate images, approve to advance to video state

### Phase 5: Video State Workflow (Complete Generation Flow)
**Goal**: Add video generation with async job management

- Build video generation endpoint (POST /api/scenes/{scene_id}/generate-video)
- Implement video regeneration endpoint (POST /api/scenes/{scene_id}/regenerate-video)
- Set up async job queue (Redis + Celery) for video generation
- Connect Replicate API for video generation
- Implement status polling endpoint (GET /api/scenes/{scene_id}/status) for SSE fallback
- Add SSE endpoint (GET /api/storyboards/{storyboard_id}/events) for real-time progress updates
- Implement Redis pub/sub for broadcasting generation status to SSE clients
- Build video player component (inline playback in scene card)
- Add "Regenerate Video" button
- Implement timeline color update (yellow → green)
- Add progress indicators during video generation
- Handle video generation errors (inline + toast)
- Add edit icon for duration in video state (with warning modal)

**Success Criteria**: Can generate videos from approved images, play videos inline, regenerate videos, track progress in real-time

### Phase 6: Preview & Final Generation (Complete Experience)
**Goal**: Add preview functionality and final video generation trigger

- Build preview endpoint (GET /api/storyboards/{storyboard_id}/preview)
- Create PreviewPlayer component (dedicated preview area)
- Implement "Preview All Scenes" button at top
- Build placeholder logic:
  - Use video if available
  - Use image with duration if no video
  - Use text display for 5s if no image
- Add concatenation logic for preview playback
- Implement "Generate Final Video" button with enabling logic (all scenes in video state)
- Add "6/6 scenes ready" indicator
- Connect to existing final composition screen
- Prevent final generation if any errors present

**Success Criteria**: Can preview concatenated video with placeholders, see progress indicator, generate final video when all scenes complete

### Phase 7: Polish & Edge Cases (Production Ready)
**Goal**: Handle all edge cases and polish user experience

- Implement "Regenerate All Scenes" button with warning modal
- Add comprehensive error handling and recovery
- Optimize carousel animations and transitions
- Add tooltips to edit icons
- Implement toast notification system
- Add comprehensive loading states
- Optimize API calls and caching
- Add retry logic for failed generations
- Implement rate limiting and queue management
- Performance testing with multiple concurrent users
- Mobile responsive adjustments
- Accessibility audit and fixes

**Success Criteria**: All workflows handle errors gracefully, smooth animations, production-ready performance

### Future Enhancements (Post-MVP)
- Drag-and-drop scene reordering
- Overall progress indicator ("2 Videos, 1 Image generating...")
- Batch operations (approve multiple scenes, regenerate subset)
- Scene duplication
- Undo/redo functionality
- Keyboard shortcuts for navigation
- Advanced duration controls (decimal precision, presets)
- Custom thumbnail selection for videos
- Scene notes/comments
- Collaboration features (team comments, approvals)

---

## Logical Dependency Chain

### Foundation Layer (Build First)
1. **Database schema and models** - Nothing works without data persistence
2. **Scene ID generation (UUID)** - Required for all scene operations
3. **Storyboard initialization endpoint** - First API call on page load
4. **Scene retrieval endpoint** - Required for page refresh recovery

### UI Foundation (Build Second)
5. **StoryboardCarousel container** - Houses all other components
6. **SceneTimeline component** - Navigation depends on this
7. **SceneCard with state layouts** - Core visual component
8. **WarningModal component** - Needed before any destructive actions

### First Working Loop (Build Third)
9. **Initial text generation** - Users need starting point
10. **Inline text editing** - Manual editing capability
11. **Text regeneration endpoint** - AI regeneration capability
12. **Approve text button** - Advances to next state
13. **Warning modal integration** - Prevents accidental data loss

### Second Working Loop (Build Fourth)
14. **Image generation endpoint** - Creates images from text
15. **Duration input field** - Required for image state
16. **Image regeneration endpoint** - Retry capability
17. **Approve image button** - Advances to video state
18. **Timeline color updates** - Visual feedback

### Complete Generation Flow (Build Fifth)
19. **Video generation endpoint** - Creates videos from images
20. **Async job queue** - Background processing
21. **SSE endpoint with Redis pub/sub** - Real-time updates
22. **Video player component** - Playback capability
23. **Video regeneration endpoint** - Retry capability
24. **Duration edit from video state** - Reversion capability

### Preview & Completion (Build Sixth)
25. **Preview endpoint** - Concatenation data
26. **PreviewPlayer component** - Shows progress
27. **Placeholder logic** - Handles incomplete scenes
28. **Final video button** - Completion trigger
29. **Progress indicator (6/6)** - Readiness display

### Polish (Build Last)
30. **Regenerate all scenes** - Nuclear option
31. **Error handling improvements** - Edge cases
32. **Performance optimizations** - Production readiness
33. **Accessibility enhancements** - Compliance
34. **Mobile responsiveness** - Cross-device support

---

## Risks and Mitigations

### Risk 1: Complex State Management
**Challenge**: Managing three states per scene across six scenes with async operations and error handling creates complex state synchronization issues.

**Mitigation**:
- Use backend as single source of truth for all state
- Implement pessimistic UI updates (wait for backend confirmation)
- Add comprehensive state validation on backend
- Use TypeScript discriminated unions for scene states
- Write extensive integration tests for state transitions
- Implement state machine pattern for scene progression

### Risk 2: Async Video Generation Performance
**Challenge**: Video generation takes 30-90 seconds per scene. Users might generate all 6 videos simultaneously, overloading the queue.

**Mitigation**:
- Implement job queue with priority management
- Add rate limiting (max 2-3 concurrent video jobs per user)
- Provide clear feedback on queue position and estimated time
- Consider implementing generation batching
- Add timeout handling and automatic retries
- Use SSE for real-time progress updates (lower overhead than polling, simpler than WebSocket)

### Risk 3: Data Loss on Regeneration
**Challenge**: Users may accidentally click regenerate or edit, losing valuable generated content.

**Mitigation**:
- Implement modal warnings for ALL destructive actions
- Add confirmation step (Yes/No, not just OK)
- Consider adding "undo" capability with version history (future enhancement)
- Store previous versions temporarily (24 hours) for recovery
- Clear labeling of consequences in warning text
- Add "Are you sure?" double confirmation for "Regenerate All Scenes"

### Risk 4: Image/Video Generation Failures
**Challenge**: External API failures or timeouts can leave scenes in inconsistent states.

**Mitigation**:
- Implement automatic retry logic (3 attempts)
- Add manual retry buttons for user control
- Store error messages with actionable guidance
- Implement graceful degradation (preview works even with errors)
- Block final video generation if any errors exist
- Add timeout handling (60s for images, 120s for videos)
- Implement webhook callbacks from Replicate for reliability

### Risk 5: Carousel UX Confusion
**Challenge**: Single-scene carousel with timeline-only navigation might confuse users expecting traditional scrolling.

**Mitigation**:
- Add onboarding tooltip on first visit ("Click timeline to switch scenes")
- Ensure smooth, obvious transitions between scenes
- Keep timeline always visible and prominent
- Add visual feedback on timeline (hover states, current scene highlight)
- Consider adding subtle arrow indicators (even if not interactive)
- Test with actual users early in development

### Risk 6: Session/State Recovery Complexity
**Challenge**: Page refreshes or browser crashes during generation must preserve all state and resume jobs.

**Mitigation**:
- Poll generation status on page load for any "generating" scenes
- Reconnect SSE stream immediately (automatic with EventSource API)
- Store job IDs persistently with scenes
- Implement idempotent generation endpoints (safe to retry)
- Add "resume generation" button if jobs detected
- Clear error messaging if jobs cannot be resumed

### Risk 7: Mobile Responsiveness
**Challenge**: Carousel and timeline interactions designed for desktop may not translate well to mobile.

**Mitigation**:
- Design mobile-first for timeline (swipeable)
- Test carousel transitions on touch devices
- Ensure modal dialogs work well on small screens
- Consider alternative layouts for mobile (stacked vs carousel)
- Add touch gesture support (swipe between scenes as alternative to timeline)
- Test on actual devices early and often

### Risk 8: Determining MVP Scope
**Challenge**: Feature set is ambitious; risk of scope creep or delayed launch if not carefully scoped.

**Mitigation**:
- Follow phased roadmap strictly (Phases 1-6 only for MVP)
- Defer drag-and-drop, batch operations, and collaboration features
- Launch with basic error handling, enhance post-launch
- Use feature flags to enable/disable non-critical features
- Set clear success metrics for MVP (complete end-to-end workflow)
- Plan for iterative releases (MVP → Enhanced → Full)

---

## Appendix

### Research Findings

**Current System Analysis:**
- Existing `SceneTimeline.tsx` shows cumulative duration visualization with colored segments
- Current `SceneCard.tsx` displays static scene number, duration badge, image, description, and style prompt
- Existing `Storyboard.tsx` uses grid layout (3 columns) with "Regenerate Scenes" and "Continue" buttons
- Scene data model includes: scene_number, duration, description, style_prompt, seed_image_url, generation_success, generation_error
- Current workflow: Moods (step 2) → Storyboard (step 3) → Video Generation (step 4) → Final Composition (step 5)

**Key Changes from Current System:**
- Grid → Carousel (1 scene at a time)
- Static display → Interactive state progression
- Bulk regeneration → Individual scene control
- Sequential workflow → Parallel independent workflows
- scene_number → UUID scene_id
- Add state field ('text' | 'image' | 'video')
- Add video_duration field (default 5)
- Add generation_status object (image/video status tracking)

### Technical Specifications

**Video Duration:**
- Range: 1-10 seconds
- Default: 5 seconds
- Input: Number field with validation
- Stored: Integer (seconds)

**Scene Generation:**
- Initial load: 6 scene texts generated automatically
- AI text generation: Uses creative brief + mood context
- Image generation: Uses scene text + mood style_prompt
- Video generation: Uses image + duration

**Timeline Dimensions:**
- Height: 80-100px
- Fixed position at top
- Full width
- Responsive on mobile (collapsible or scrollable)

**Carousel Dimensions:**
- Single scene card: Max width 1200px, centered
- Aspect ratio: Flexible based on content (primarily 9:16 for video/image)
- Transition: 300ms ease-in-out horizontal slide

**Color Coding:**
- Text state: `hsl(220, 10%, 40%)` (Gray)
- Image state: `hsl(45, 90%, 60%)` (Yellow)
- Video state: `hsl(140, 70%, 50%)` (Green)
- Error state: `hsl(0, 70%, 50%)` (Red)
- Generating: Pulsing animation on current color

**Generation Timeouts:**
- Text generation: 30 seconds
- Image generation: 60 seconds
- Video generation: 120 seconds
- SSE heartbeat interval: 15 seconds (keeps connection alive)
- SSE reconnect: Automatic via EventSource API (3-second default)

**SSE Implementation Details:**
- Endpoint: `GET /api/storyboards/{storyboard_id}/events`
- Content-Type: `text/event-stream`
- Event format: `event: scene_update\ndata: {json}\n\n`
- Payload: `{ scene_id, state, status, progress_percent, video_url?, error? }`
- Backend: FastAPI StreamingResponse with Redis pub/sub for event broadcasting
- Frontend: Native EventSource API with automatic reconnection
- Fallback: Polling endpoint for browsers without SSE support

**Error Handling:**
- Inline error: Red border on scene card + error message below element
- Toast notification: 5-second display at top of screen
- Retry button: Appears immediately on error
- Error prevention: Disable "Generate Final Video" if any scene has error
